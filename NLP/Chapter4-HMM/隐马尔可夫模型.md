# 隐马科夫链  
## 马科夫链  
每个状态的转移只依赖于之前的n个状态，这个过程称为1一个n阶的模型。  
其中，n是影响转移状态的数目，最简单的马尔科夫过程就是一阶过程。  
每一个状态的转移只依赖于其之前的那一个状态。  
数学表达如下：  
![PicName](https://github.com/jiaruncao/jiaruncao.github.io/blob/master/NLP/Chapter4-HMM/formula/17.png)  
  
  
#### 马科夫链的缺点  
前后关系的缺失，导致了信息的缺失。  
因此，引入隐马可夫链（HMM）：  
HMM是一种统计模型，用来描述一个含有隐含未知参数的马尔科夫过程。  
**其难点在于从课观测的参数中确定该过程的隐含参数，然后利用这些参数做进一步的分析**  
### HMM  
为了解释HMM，我们以掷骰子为例，存在3个骰子：D6,D4,D8，每次选中某个骰子的可能性为1/3（**转换状态，每次选取下一个筛子的概率称为转换概率，可以人为设定**）  

  
  ![PicName](https://github.com/jiaruncao/jiaruncao.github.io/blob/master/NLP/Chapter4-HMM/formula/18.png)  
    
    

  
  
经过N次掷骰子过后，我们可以得到一个结果序列（1，3，8，2，5，7...），因为其状态是我们可以观察到的，因此我们称之为**可见链**  
而该结果序列中的每一个值是由哪个骰子得到的呢？我们可以得到一个骰子序列（D4,D8,D6,D8,D4,D6...），而这个序列是我们无法得知的，因此称之为**隐性链**  
以一个图为例：  
![PicName](https://github.com/jiaruncao/jiaruncao.github.io/blob/master/NLP/Chapter4-HMM/formula/19.png)  
  
  

有点类似于RNN的结构...可以以RNN的序列结构来理解HMM  
### HMM的三大经典问题  
* **Recognition**：知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子的结果（可见状态链），求每次掷出来的都是哪种骰子（隐含状态链）  
* **Evaluation**：知道骰子有几种（隐含状态数量），每种骰子是什么（转换概率），根据掷骰子的结果（可见状态链），求掷出这个结果序列的概率
* **Training**：知道骰子有几种（隐含状态数量），不知道每种骰子是什么（转换概率），观测过很多掷骰子的结果（可见状态链），求每种骰子是什么（转换概率）  
Evaluation解法：  
> 1. 遍历隐性链的各种可能性，求条件概率，选择最大的作为该序列
> 2. 前向算法：以序列模型为基础，算前一步的综合概率，求当前结果的概率
> 3. 后向算法：确定最后一个结果的序列，往前倒退，因为最后一个结果是确定的，所以其初始概率是1  
  
Recognition解法：  
> Viterbi算法：在已知观测序列的情况下，计算各种可能的隐含状态序列的可能性，取最大值  
Training解法：  
> Baum-Welch算法  


